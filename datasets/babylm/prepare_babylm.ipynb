{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading builder script: 100%|██████████| 13.7k/13.7k [00:00<00:00, 2.96MB/s]\n",
      "Downloading readme: 100%|██████████| 4.73k/4.73k [00:00<00:00, 2.20MB/s]\n",
      "Downloading data: 100%|██████████| 99.8M/99.8M [00:04<00:00, 21.5MB/s]\n",
      "Downloading data: 100%|██████████| 225M/225M [00:10<00:00, 21.8MB/s] \n",
      "Downloading data: 100%|██████████| 133M/133M [00:05<00:00, 23.9MB/s] \n",
      "Downloading data: 100%|██████████| 90.7M/90.7M [00:04<00:00, 19.1MB/s]\n",
      "Downloading data: 100%|██████████| 274M/274M [00:10<00:00, 25.0MB/s] \n",
      "Downloading data: 100%|██████████| 920M/920M [00:41<00:00, 22.1MB/s] \n",
      "Downloading data: 100%|██████████| 292M/292M [00:13<00:00, 22.2MB/s] \n",
      "Downloading data: 100%|██████████| 430M/430M [00:18<00:00, 23.4MB/s] \n",
      "Downloading data: 100%|██████████| 34.5M/34.5M [00:01<00:00, 21.0MB/s]\n",
      "Downloading data: 100%|██████████| 295M/295M [00:13<00:00, 21.9MB/s] \n",
      "Downloading data: 100%|██████████| 9.72M/9.72M [00:00<00:00, 14.3MB/s]\n",
      "Downloading data: 100%|██████████| 23.6M/23.6M [00:00<00:00, 24.4MB/s]\n",
      "Downloading data: 100%|██████████| 6.13M/6.13M [00:00<00:00, 11.6MB/s]\n",
      "Downloading data: 100%|██████████| 7.29M/7.29M [00:00<00:00, 15.5MB/s]\n",
      "Downloading data: 100%|██████████| 24.7M/24.7M [00:00<00:00, 25.3MB/s]\n",
      "Downloading data: 100%|██████████| 87.4M/87.4M [00:03<00:00, 27.1MB/s]\n",
      "Downloading data: 100%|██████████| 27.6M/27.6M [00:01<00:00, 26.6MB/s]\n",
      "Downloading data: 100%|██████████| 46.0M/46.0M [00:01<00:00, 25.5MB/s]\n",
      "Downloading data: 100%|██████████| 3.81M/3.81M [00:00<00:00, 8.46MB/s]\n",
      "Downloading data: 100%|██████████| 33.6M/33.6M [00:01<00:00, 25.0MB/s]\n",
      "Downloading data: 100%|██████████| 8.03M/8.03M [00:00<00:00, 10.8MB/s]\n",
      "Downloading data: 100%|██████████| 25.8M/25.8M [00:01<00:00, 22.0MB/s]\n",
      "Downloading data: 100%|██████████| 7.93M/7.93M [00:00<00:00, 11.4MB/s]\n",
      "Downloading data: 100%|██████████| 9.15M/9.15M [00:00<00:00, 11.9MB/s]\n",
      "Downloading data: 100%|██████████| 33.4M/33.4M [00:01<00:00, 21.0MB/s]\n",
      "Downloading data: 100%|██████████| 81.8M/81.8M [00:03<00:00, 21.9MB/s]\n",
      "Downloading data: 100%|██████████| 34.4M/34.4M [00:01<00:00, 24.9MB/s]\n",
      "Downloading data: 100%|██████████| 53.3M/53.3M [00:02<00:00, 23.9MB/s]\n",
      "Downloading data: 100%|██████████| 4.32M/4.32M [00:00<00:00, 8.26MB/s]\n",
      "Downloading data: 100%|██████████| 35.9M/35.9M [00:01<00:00, 23.7MB/s]\n",
      "Generating train split: 10175723 examples [01:44, 97731.86 examples/s]\n",
      "Generating validation split: 985958 examples [00:10, 97133.85 examples/s] \n",
      "Generating test split: 1008786 examples [00:10, 98204.10 examples/s]\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "\n",
    "# Load cambridge-climb/BabyLM dataset\n",
    "dataset = datasets.load_dataset(\"cambridge-climb/BabyLM\", \"original_strict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataset['train'].to_pandas()\n",
    "df = df.drop(columns=['tagged_text'])\n",
    "df['is_child'] = False\n",
    "df['target_child_age'] = 0.2\n",
    "df = df.rename(columns={'text': 'processed_gloss'})\n",
    "df['language_code'] = 'en-us'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phonemizing using language \"EnglishNA\"...\n",
      "Using espeak backend with language code \"en-us\"...\n"
     ]
    }
   ],
   "source": [
    "# Import phonemize\n",
    "import sys\n",
    "import os\n",
    "os.environ['PHONEMIZER_ESPEAK_LIBRARY'] = '/opt/local/lib/libespeak-ng.dylib'\n",
    "sys.path.append('../../')\n",
    "from src.phonemize import phonemize_utterances, character_split_utterance\n",
    "\n",
    "lines = df['processed_gloss'].tolist()\n",
    "phonemized_lines = phonemize_utterances(lines)\n",
    "df['phonemized_utterance'] = phonemized_lines\n",
    "df['character_split_utterance'] = character_split_utterance(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: 0 lines were not phonemized successfully. Dropping these.\n"
     ]
    }
   ],
   "source": [
    "num_empty = len(df[df['phonemized_utterance'] == ''])\n",
    "print(f'WARNING: {num_empty} lines were not phonemized successfully. Dropping these.')\n",
    "df = df[df['phonemized_utterance'] != '']\n",
    "df['character_split_utterance'] = character_split_utterance(df['processed_gloss'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('BabyLM-phonemized/train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phonemizing using language \"EnglishNA\"...\n",
      "Using espeak backend with language code \"en-us\"...\n",
      "WARNING: 248655 lines were not phonemized successfully. Dropping these.\n"
     ]
    }
   ],
   "source": [
    "df = dataset['validation'].to_pandas()\n",
    "df = df.drop(columns=['tagged_text'])\n",
    "df['is_child'] = False\n",
    "df['target_child_age'] = 0.2\n",
    "df = df.rename(columns={'text': 'processed_gloss'})\n",
    "df['language_code'] = 'en-us'\n",
    "\n",
    "lines = df['processed_gloss'].tolist()\n",
    "phonemized_lines = phonemize_utterances(lines)\n",
    "df['phonemized_utterance'] = phonemized_lines\n",
    "df['character_split_utterance'] = character_split_utterance(lines)\n",
    "\n",
    "num_empty = len(df[df['phonemized_utterance'] == ''])\n",
    "print(f'WARNING: {num_empty} lines were not phonemized successfully. Dropping these.')\n",
    "df = df[df['phonemized_utterance'] != '']\n",
    "df['character_split_utterance'] = character_split_utterance(df['processed_gloss'].tolist())\n",
    "\n",
    "# Subsamples the validation set to 1000 examples\n",
    "df = df.sample(n=10000, random_state=42)\n",
    "\n",
    "df.to_csv('BabyLM-phonemized/valid.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 7552848 examples [00:35, 211150.26 examples/s]\n",
      "Generating valid split: 737303 examples [00:03, 211874.02 examples/s]\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset_new = load_dataset('BabyLM-phonemized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
